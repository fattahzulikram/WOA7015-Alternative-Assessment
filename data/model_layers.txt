vision_model.encoder.layers.0.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.0.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.0.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.0.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.1.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.1.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.1.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.1.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.2.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.2.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.2.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.2.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.3.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.3.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.3.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.3.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.4.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.4.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.4.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.4.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.5.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.5.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.5.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.5.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.6.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.6.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.6.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.6.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.7.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.7.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.7.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.7.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.8.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.8.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.8.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.8.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.9.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.9.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.9.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.9.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.10.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.10.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.10.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.10.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.11.self_attn<class 'transformers.models.blip.modeling_blip.BlipAttention'>
vision_model.encoder.layers.11.self_attn.dropout<class 'torch.nn.modules.dropout.Dropout'>
vision_model.encoder.layers.11.self_attn.qkv<class 'torch.nn.modules.linear.Linear'>
vision_model.encoder.layers.11.self_attn.projection<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.0.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.0.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.0.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.0.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.0.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.0.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.0.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.0.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.0.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.0.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.0.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.0.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.0.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.0.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.0.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.0.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.0.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.0.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.0.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.0.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.1.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.1.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.1.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.1.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.1.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.1.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.1.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.1.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.1.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.1.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.1.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.1.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.1.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.1.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.1.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.1.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.1.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.1.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.1.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.1.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.2.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.2.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.2.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.2.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.2.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.2.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.2.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.2.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.2.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.2.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.2.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.2.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.2.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.2.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.2.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.2.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.2.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.2.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.2.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.2.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.3.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.3.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.3.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.3.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.3.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.3.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.3.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.3.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.3.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.3.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.3.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.3.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.3.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.3.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.3.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.3.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.3.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.3.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.3.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.3.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.4.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.4.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.4.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.4.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.4.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.4.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.4.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.4.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.4.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.4.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.4.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.4.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.4.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.4.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.4.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.4.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.4.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.4.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.4.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.4.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.5.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.5.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.5.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.5.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.5.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.5.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.5.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.5.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.5.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.5.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.5.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.5.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.5.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.5.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.5.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.5.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.5.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.5.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.5.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.5.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.6.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.6.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.6.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.6.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.6.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.6.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.6.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.6.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.6.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.6.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.6.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.6.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.6.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.6.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.6.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.6.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.6.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.6.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.6.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.6.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.7.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.7.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.7.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.7.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.7.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.7.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.7.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.7.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.7.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.7.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.7.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.7.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.7.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.7.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.7.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.7.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.7.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.7.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.7.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.7.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.8.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.8.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.8.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.8.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.8.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.8.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.8.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.8.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.8.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.8.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.8.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.8.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.8.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.8.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.8.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.8.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.8.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.8.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.8.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.8.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.9.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.9.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.9.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.9.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.9.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.9.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.9.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.9.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.9.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.9.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.9.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.9.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.9.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.9.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.9.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.9.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.9.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.9.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.9.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.9.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.10.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.10.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.10.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.10.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.10.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.10.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.10.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.10.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.10.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.10.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.10.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.10.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.10.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.10.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.10.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.10.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.10.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.10.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.10.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.10.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.11.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.11.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.11.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.11.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.11.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.11.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.11.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.11.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.11.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.11.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.11.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_encoder.encoder.layer.11.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_encoder.encoder.layer.11.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.11.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.11.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.11.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_encoder.encoder.layer.11.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_encoder.encoder.layer.11.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_encoder.encoder.layer.11.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_encoder.encoder.layer.11.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.0.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.0.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.0.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.0.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.0.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.0.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.0.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.0.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.0.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.0.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.0.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.0.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.0.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.0.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.0.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.0.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.0.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.0.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.0.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.0.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.1.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.1.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.1.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.1.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.1.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.1.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.1.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.1.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.1.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.1.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.1.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.1.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.1.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.1.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.1.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.1.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.1.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.1.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.1.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.1.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.2.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.2.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.2.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.2.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.2.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.2.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.2.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.2.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.2.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.2.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.2.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.2.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.2.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.2.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.2.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.2.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.2.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.2.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.2.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.2.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.3.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.3.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.3.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.3.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.3.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.3.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.3.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.3.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.3.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.3.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.3.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.3.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.3.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.3.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.3.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.3.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.3.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.3.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.3.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.3.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.4.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.4.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.4.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.4.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.4.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.4.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.4.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.4.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.4.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.4.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.4.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.4.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.4.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.4.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.4.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.4.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.4.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.4.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.4.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.4.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.5.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.5.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.5.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.5.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.5.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.5.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.5.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.5.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.5.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.5.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.5.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.5.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.5.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.5.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.5.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.5.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.5.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.5.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.5.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.5.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.6.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.6.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.6.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.6.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.6.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.6.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.6.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.6.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.6.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.6.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.6.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.6.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.6.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.6.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.6.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.6.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.6.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.6.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.6.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.6.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.7.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.7.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.7.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.7.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.7.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.7.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.7.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.7.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.7.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.7.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.7.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.7.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.7.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.7.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.7.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.7.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.7.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.7.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.7.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.7.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.8.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.8.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.8.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.8.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.8.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.8.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.8.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.8.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.8.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.8.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.8.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.8.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.8.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.8.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.8.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.8.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.8.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.8.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.8.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.8.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.9.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.9.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.9.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.9.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.9.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.9.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.9.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.9.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.9.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.9.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.9.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.9.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.9.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.9.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.9.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.9.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.9.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.9.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.9.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.9.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.10.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.10.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.10.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.10.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.10.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.10.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.10.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.10.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.10.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.10.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.10.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.10.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.10.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.10.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.10.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.10.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.10.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.10.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.10.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.10.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.11.attention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.11.attention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.11.attention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.11.attention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.11.attention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.11.attention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.11.attention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.11.attention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.11.attention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.11.attention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.11.crossattention<class 'transformers.models.blip.modeling_blip_text.BlipTextAttention'>
text_decoder.bert.encoder.layer.11.crossattention.self<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfAttention'>
text_decoder.bert.encoder.layer.11.crossattention.self.query<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.11.crossattention.self.key<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.11.crossattention.self.value<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.11.crossattention.self.dropout<class 'torch.nn.modules.dropout.Dropout'>
text_decoder.bert.encoder.layer.11.crossattention.output<class 'transformers.models.blip.modeling_blip_text.BlipTextSelfOutput'>
text_decoder.bert.encoder.layer.11.crossattention.output.dense<class 'torch.nn.modules.linear.Linear'>
text_decoder.bert.encoder.layer.11.crossattention.output.LayerNorm<class 'torch.nn.modules.normalization.LayerNorm'>
text_decoder.bert.encoder.layer.11.crossattention.output.dropout<class 'torch.nn.modules.dropout.Dropout'>
